{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 - Pandas Introduction\n",
    "All questions are weighted the same in this assignment.\n",
    "## Part 1\n",
    "The following code loads the olympics dataset (olympics.csv), which was derrived from the Wikipedia entry on [All Time Olympic Games Medals](https://en.wikipedia.org/wiki/All-time_Olympic_Games_medal_table), and does some basic data cleaning. \n",
    "\n",
    "The columns are organized as # of Summer games, Summer medals, # of Winter games, Winter medals, total # number of games, total # of medals. Use this dataset to answer the questions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "1",
     "locked": false,
     "solution": false
    },
    "umich_question": "prolog-000"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('olympics.csv', index_col=0, skiprows=1)\n",
    "\n",
    "for col in df.columns:\n",
    "    if col[:2]=='01':\n",
    "        df.rename(columns={col:'Gold'+col[4:]}, inplace=True)\n",
    "    if col[:2]=='02':\n",
    "        df.rename(columns={col:'Silver'+col[4:]}, inplace=True)\n",
    "    if col[:2]=='03':\n",
    "        df.rename(columns={col:'Bronze'+col[4:]}, inplace=True)\n",
    "    if col[:1]=='â„–':\n",
    "        df.rename(columns={col:'#'+col[1:]}, inplace=True)\n",
    "\n",
    "names_ids = df.index.str.split('\\s\\(') # split the index by '('\n",
    "\n",
    "df.index = names_ids.str[0] # the [0] element is the country name (new index) \n",
    "df['ID'] = names_ids.str[1].str[:3] # the [1] element is the abbreviation or ID (take first 3 characters from that)\n",
    "\n",
    "df = df.drop('Totals')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 0 (Example)\n",
    "\n",
    "What is the first country in df? *This function should return a Series.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "umich_question": "000"
   },
   "outputs": [],
   "source": [
    "def answer_zero():\n",
    "    return df.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "Which country has won the most gold medals in summer games?\n",
    "\n",
    "*This function should return a single string value.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    },
    "umich_part_id": "001",
    "umich_partlist_id": "001"
   },
   "outputs": [],
   "source": [
    "def answer_one():\n",
    "    return df.loc[df['Gold'] == df['Gold'].max()].iloc[0].name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "Which country had the biggest difference between their summer and winter gold medal counts?\n",
    "\n",
    "*This function should return a single string value.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "umich_part_id": "002",
    "umich_partlist_id": "001"
   },
   "outputs": [],
   "source": [
    "def answer_two():\n",
    "    df['winter_summer_gold_diff'] = (df['Gold'].fillna(0) - df['Gold.1'].fillna(0))\n",
    "    df['winter_summer_gold_diff'] = df['winter_summer_gold_diff'].abs()\n",
    "    return df.loc[df['winter_summer_gold_diff'] == df['winter_summer_gold_diff'].max()].iloc[0].name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "Which country has the biggest difference between their summer gold medal counts and winter gold medal counts relative to their total gold medal count? \n",
    "\n",
    "$$\\frac{Summer~Gold - Winter~Gold}{Total~Gold}$$\n",
    "\n",
    "Only include countries that have won at least 1 gold in both summer and winter.\n",
    "\n",
    "*This function should return a single string value.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "umich_part_id": "003",
    "umich_partlist_id": "001"
   },
   "outputs": [],
   "source": [
    "def answer_three():\n",
    "    new_df = df.loc[df['Gold'] != 0]\n",
    "    new_df = new_df.loc[df['Gold.1'] != 0]\n",
    "    new_df['winter_summer_gold_diff'] = (new_df['Gold'].fillna(0) - new_df['Gold.1'].fillna(0))\n",
    "    new_df['winter_summer_gold_diff'] = new_df['winter_summer_gold_diff'].abs()\n",
    "    new_df['winter_summer_gold_diff_ratio'] = new_df['winter_summer_gold_diff'].divide(new_df[['Gold', 'Gold.1', 'Gold.2']].fillna(0).sum(axis=1))\n",
    "    return new_df.loc[new_df['winter_summer_gold_diff_ratio'] == new_df['winter_summer_gold_diff_ratio'].max()].iloc[0].name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "Write a function that creates a Series called \"Points\" which is a weighted value where each gold medal (`Gold.2`) counts for 3 points, silver medals (`Silver.2`) for 2 points, and bronze medals (`Bronze.2`) for 1 point. The function should return only the column (a Series object) which you created, with the country names as indices.\n",
    "\n",
    "*This function should return a Series named `Points` of length 146*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "umich_part_id": "004",
    "umich_partlist_id": "001"
   },
   "outputs": [],
   "source": [
    "def answer_four():\n",
    "    df['question_4'] = df['Gold.2']*3 + df['Silver.2']*2 + df['Bronze.2']\n",
    "    return df['question_4']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "For the next set of questions, we will be using census data from the [United States Census Bureau](http://www.census.gov). Counties are political and geographic subdivisions of states in the United States. This dataset contains population data for counties and states in the US from 2010 to 2015. [See this document](https://www2.census.gov/programs-surveys/popest/technical-documentation/file-layouts/2010-2015/co-est2015-alldata.pdf) for a description of the variable names.\n",
    "\n",
    "The census dataset (census.csv) should be loaded as census_df. Answer questions using this as appropriate.\n",
    "\n",
    "### Question 5\n",
    "Which state has the most counties in it? (hint: consider the sumlevel key carefully! You'll need this for future questions too...)\n",
    "\n",
    "*This function should return a single string value.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "umich_question": "prolog-005"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STNAME</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>CENSUS2010POP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>73</td>\n",
       "      <td>658466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>97</td>\n",
       "      <td>412992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>89</td>\n",
       "      <td>334811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>20</td>\n",
       "      <td>291826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>90</td>\n",
       "      <td>97581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>170</td>\n",
       "      <td>88995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>13</td>\n",
       "      <td>3817117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>19</td>\n",
       "      <td>980263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>21</td>\n",
       "      <td>375770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>119</td>\n",
       "      <td>382748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>7</td>\n",
       "      <td>221339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>143</td>\n",
       "      <td>203065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>California</td>\n",
       "      <td>37</td>\n",
       "      <td>9818605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>California</td>\n",
       "      <td>73</td>\n",
       "      <td>3095313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>California</td>\n",
       "      <td>59</td>\n",
       "      <td>3010232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Colorado</td>\n",
       "      <td>31</td>\n",
       "      <td>600158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Colorado</td>\n",
       "      <td>5</td>\n",
       "      <td>572003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Colorado</td>\n",
       "      <td>41</td>\n",
       "      <td>622263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Connecticut</td>\n",
       "      <td>1</td>\n",
       "      <td>916829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Connecticut</td>\n",
       "      <td>3</td>\n",
       "      <td>894014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Connecticut</td>\n",
       "      <td>9</td>\n",
       "      <td>862477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Delaware</td>\n",
       "      <td>3</td>\n",
       "      <td>538479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Delaware</td>\n",
       "      <td>5</td>\n",
       "      <td>197145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Delaware</td>\n",
       "      <td>1</td>\n",
       "      <td>162310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>1</td>\n",
       "      <td>601723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Florida</td>\n",
       "      <td>86</td>\n",
       "      <td>2496435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Florida</td>\n",
       "      <td>11</td>\n",
       "      <td>1748066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Florida</td>\n",
       "      <td>99</td>\n",
       "      <td>1320134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Georgia</td>\n",
       "      <td>121</td>\n",
       "      <td>920581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Georgia</td>\n",
       "      <td>135</td>\n",
       "      <td>805321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>South Dakota</td>\n",
       "      <td>83</td>\n",
       "      <td>44828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>South Dakota</td>\n",
       "      <td>103</td>\n",
       "      <td>100948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>South Dakota</td>\n",
       "      <td>99</td>\n",
       "      <td>169468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>Tennessee</td>\n",
       "      <td>157</td>\n",
       "      <td>927644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>Tennessee</td>\n",
       "      <td>37</td>\n",
       "      <td>626681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>Tennessee</td>\n",
       "      <td>93</td>\n",
       "      <td>432226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>Texas</td>\n",
       "      <td>201</td>\n",
       "      <td>4092459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>Texas</td>\n",
       "      <td>113</td>\n",
       "      <td>2368139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>Texas</td>\n",
       "      <td>439</td>\n",
       "      <td>1809034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>Utah</td>\n",
       "      <td>11</td>\n",
       "      <td>306479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>Utah</td>\n",
       "      <td>35</td>\n",
       "      <td>1029655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>Utah</td>\n",
       "      <td>49</td>\n",
       "      <td>516564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>Vermont</td>\n",
       "      <td>7</td>\n",
       "      <td>156545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>Vermont</td>\n",
       "      <td>21</td>\n",
       "      <td>61642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>Vermont</td>\n",
       "      <td>23</td>\n",
       "      <td>59534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>59</td>\n",
       "      <td>1081726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>810</td>\n",
       "      <td>437994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>153</td>\n",
       "      <td>402002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>Washington</td>\n",
       "      <td>33</td>\n",
       "      <td>1931249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>Washington</td>\n",
       "      <td>53</td>\n",
       "      <td>795225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>Washington</td>\n",
       "      <td>61</td>\n",
       "      <td>713335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>West Virginia</td>\n",
       "      <td>3</td>\n",
       "      <td>104169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>West Virginia</td>\n",
       "      <td>39</td>\n",
       "      <td>193063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>West Virginia</td>\n",
       "      <td>11</td>\n",
       "      <td>96319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>25</td>\n",
       "      <td>488073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>79</td>\n",
       "      <td>947735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>133</td>\n",
       "      <td>389891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>25</td>\n",
       "      <td>75450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>21</td>\n",
       "      <td>91738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>5</td>\n",
       "      <td>46133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   STNAME  COUNTY  CENSUS2010POP\n",
       "0                 Alabama      73         658466\n",
       "1                 Alabama      97         412992\n",
       "2                 Alabama      89         334811\n",
       "3                  Alaska      20         291826\n",
       "4                  Alaska      90          97581\n",
       "5                  Alaska     170          88995\n",
       "6                 Arizona      13        3817117\n",
       "7                 Arizona      19         980263\n",
       "8                 Arizona      21         375770\n",
       "9                Arkansas     119         382748\n",
       "10               Arkansas       7         221339\n",
       "11               Arkansas     143         203065\n",
       "12             California      37        9818605\n",
       "13             California      73        3095313\n",
       "14             California      59        3010232\n",
       "16               Colorado      31         600158\n",
       "17               Colorado       5         572003\n",
       "15               Colorado      41         622263\n",
       "18            Connecticut       1         916829\n",
       "19            Connecticut       3         894014\n",
       "20            Connecticut       9         862477\n",
       "21               Delaware       3         538479\n",
       "22               Delaware       5         197145\n",
       "23               Delaware       1         162310\n",
       "24   District of Columbia       1         601723\n",
       "25                Florida      86        2496435\n",
       "26                Florida      11        1748066\n",
       "27                Florida      99        1320134\n",
       "28                Georgia     121         920581\n",
       "29                Georgia     135         805321\n",
       "..                    ...     ...            ...\n",
       "123          South Dakota      83          44828\n",
       "122          South Dakota     103         100948\n",
       "121          South Dakota      99         169468\n",
       "124             Tennessee     157         927644\n",
       "125             Tennessee      37         626681\n",
       "126             Tennessee      93         432226\n",
       "127                 Texas     201        4092459\n",
       "128                 Texas     113        2368139\n",
       "129                 Texas     439        1809034\n",
       "132                  Utah      11         306479\n",
       "130                  Utah      35        1029655\n",
       "131                  Utah      49         516564\n",
       "133               Vermont       7         156545\n",
       "134               Vermont      21          61642\n",
       "135               Vermont      23          59534\n",
       "136              Virginia      59        1081726\n",
       "137              Virginia     810         437994\n",
       "138              Virginia     153         402002\n",
       "139            Washington      33        1931249\n",
       "140            Washington      53         795225\n",
       "141            Washington      61         713335\n",
       "143         West Virginia       3         104169\n",
       "142         West Virginia      39         193063\n",
       "144         West Virginia      11          96319\n",
       "146             Wisconsin      25         488073\n",
       "145             Wisconsin      79         947735\n",
       "147             Wisconsin     133         389891\n",
       "149               Wyoming      25          75450\n",
       "148               Wyoming      21          91738\n",
       "150               Wyoming       5          46133\n",
       "\n",
       "[151 rows x 3 columns]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census_df = pd.read_csv('census.csv')\n",
    "new_df = census_df.loc[census_df['SUMLEV'] == 50]\n",
    "new_df = new_df.set_index('COUNTY').groupby('STNAME')['CENSUS2010POP'].nlargest(3).reset_index()\n",
    "new_df.sort_values('STNAME').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "umich_part_id": "005",
    "umich_partlist_id": "002"
   },
   "outputs": [],
   "source": [
    "def answer_five():\n",
    "    new_df = census_df.loc[census_df['SUMLEV'] == 50, ['SUMLEV', 'STNAME']].groupby('STNAME').count()\n",
    "    return new_df[new_df['SUMLEV'] == new_df['SUMLEV'].max()].iloc[0].name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "**Only looking at the three most populous counties for each state**, what are the three most populous states (in order of highest population to lowest population)? Use `CENSUS2010POP`.\n",
    "\n",
    "*This function should return a list of string values.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "umich_part_id": "006",
    "umich_partlist_id": "002"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['California', 'Texas', 'Illinois']"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_six():\n",
    "    new_df = census_df.loc[census_df['SUMLEV'] == 50]\n",
    "    new_df = new_df.set_index('COUNTY').groupby('STNAME')['CENSUS2010POP'].nlargest(3).reset_index()\n",
    "    new_df = new_df.groupby('STNAME')[['CENSUS2010POP']].sum().reset_index()\n",
    "    \n",
    "    return new_df.sort_values('CENSUS2010POP', ascending=False).head(3)['STNAME'].tolist()\n",
    "answer_six()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "Which county has had the largest absolute change in population within the period 2010-2015? (Hint: population values are stored in columns POPESTIMATE2010 through POPESTIMATE2015, you need to consider all six columns.)\n",
    "\n",
    "e.g. If County Population in the 5 year period is 100, 120, 80, 105, 100, 130, then its largest change in the period would be |130-80| = 50.\n",
    "\n",
    "*This function should return a single string value.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "umich_part_id": "007",
    "umich_partlist_id": "002"
   },
   "outputs": [],
   "source": [
    "def answer_seven():\n",
    "    new_df = census_df.loc[census_df['SUMLEV'] == 50]\n",
    "    new_df['POP_MAX'] = new_df[['POPESTIMATE2010', 'POPESTIMATE2011', 'POPESTIMATE2012', 'POPESTIMATE2013', 'POPESTIMATE2014', 'POPESTIMATE2015']].max(axis=1)\n",
    "    new_df['POP_MIN'] = new_df[['POPESTIMATE2010', 'POPESTIMATE2011', 'POPESTIMATE2012', 'POPESTIMATE2013', 'POPESTIMATE2014', 'POPESTIMATE2015']].min(axis=1)\n",
    "    new_df['POP_CHANGE'] = (new_df['POP_MAX']-new_df['POP_MIN']).abs()\n",
    "    return new_df.loc[new_df['POP_CHANGE'] == new_df['POP_CHANGE'].max(), 'CTYNAME'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "In this datafile, the United States is broken up into four regions using the \"REGION\" column. \n",
    "\n",
    "Create a query that finds the counties that belong to regions 1 or 2, whose name starts with 'Washington', and whose POPESTIMATE2015 was greater than their POPESTIMATE 2014.\n",
    "\n",
    "*This function should return a 5x2 DataFrame with the columns = ['STNAME', 'CTYNAME'] and the same index ID as the census_df (sorted ascending by index).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "umich_part_id": "008",
    "umich_partlist_id": "002"
   },
   "outputs": [],
   "source": [
    "def answer_eight():\n",
    "    region_filter = census_df.loc[census_df['REGION'].isin([1,2])]\n",
    "    washington_filter = region_filter.loc[region_filter['CTYNAME'].str.startswith('Washington')]\n",
    "    pop_filter = washington_filter.loc[washington_filter['POPESTIMATE2015'] > washington_filter['POPESTIMATE2014']]\n",
    "    return pop_filter[['STNAME', 'CTYNAME']].sort_index()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "coursera": {
   "course_slug": "python-data-analysis",
   "graded_item_id": "tHmgx",
   "launcher_item_id": "Um6Bz",
   "part_id": "OQsnr"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "umich": {
   "id": "Assignment 2",
   "version": "1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
